{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to install these packages before running:\n",
    "# pip install requests\n",
    "# pip install bs4\n",
    "# pip install json\n",
    "\n",
    "import requests  #requests module is used to fetch the HTML code from a webpage\n",
    "from bs4 import BeautifulSoup  #beautiful soup is a module used to parse HTML code using its various functions\n",
    "import json  #json is a module used to convert the python dictionary into a JSON string that can be written into a file\n",
    "\n",
    "\n",
    "\n",
    "trail_data = []\n",
    "\n",
    "#Here is creating a function for all the trails data in the city or state\n",
    "\n",
    "#the variable url inthe url_from_trail(plc_name) function gives the links of all the trails.\n",
    "#that links are used in this function\n",
    "def get_data_from_url(url):\n",
    "    page = requests.get(url)\n",
    "    #The HTML of the website formed by the url is retrieved by the get function and stored in page\n",
    "    \n",
    "    #Then we use the python library BeautifulSoup to parse the HTML code, by creating a soup of the contents of the retrieved HTML codes of the webpage\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    #print (soup)\n",
    "    \n",
    "    \n",
    "    #print (soup.find_all('div', {'class': 'small-12 medium-4 columns facts'})) #Used to retrieve all the HTML lines of code having the <div> class=small-12 medium-4 columns facts tag and it is assinged to the variable ddd\n",
    "    ddd = soup.find_all('div', {'class': 'small-12 medium-4 columns facts'})\n",
    "    \n",
    "    #these codes are used to retrieve the trail facts such as counties,states,length,trail_end_points,trail_surfaces,trail_category and trail_activities\n",
    "    ex = {str(i.text.replace(\":\",\"\").strip()): str(j.text.strip()) for i,j in zip(ddd[0].find_all('strong'),ddd[0].find_all('span'))}\n",
    "  \n",
    "    ex2 = {str(i.text.replace(\":\",\"\").strip()): str(j.text.strip()) for i,j in zip(ddd[1].find_all('strong'),ddd[1].find_all('span'))}\n",
    "    \n",
    "    ex3 = {str(ddd[1].find_all('strong')[-1].text).replace(\":\",\"\").strip() : [str(i.text) for i in ddd[1].find_all('a')]}\n",
    "  \n",
    "    return ex, ex2 ,ex3\n",
    "\n",
    "\n",
    "#In the website all the links are same ,but the city or state name is change at the end of the link\n",
    "#Here is creating a function that replaces the link by required data of city or state name\n",
    "\n",
    "def url_from_trail(plc_name):\n",
    "    \n",
    "    #https://www.traillink.com/trailsearch/?mmloc=\"+plc_name -Is the webpage i'm parsing in this script\n",
    "     \n",
    "    \n",
    "    url = \"https://www.traillink.com/trailsearch/?mmloc=\"+plc_name\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    #The HTML of the website formed by the url is retrieved by the get function and stored in page\n",
    "    \n",
    "    #Then we use the python library BeautifulSoup to parse the HTML code, by creating a soup of the contents of the retrieved HTML codes of the webpage\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    \n",
    "    #print (soup)\n",
    "    \n",
    "    #print (soup.find('div', {'class': 'trails'})) #Used to retrieve all the HTML lines of code having the <div> class = trails tag and it is assinged to the variable soup_div_trails\n",
    "    \n",
    "    soup_div_trails = soup.find('div', {'class': 'trails'})\n",
    "  \n",
    "    #print (soup_div_trails.find_all(\"a\")) #Used to retrieve all the HTML lines of code having the <a> tag in the variable soup_div_trails and it assigned to the variable url\n",
    "    \n",
    "    #It gives the all the trail links and the link concatinate with the base url - https://www.traillink.com\n",
    "    url = [\"https://www.traillink.com\"+str(i['href']) for i in soup_div_trails.find_all('a', href=True)]\n",
    "    \n",
    "    #print soup_div_trails.find_all('div', {'class': 'row collapse trail'}) #Used to retrieve all the HTML lines of code having the <div> class=row collapse trail tag in the variable soup_div_trails and it assigned to the variable desc\n",
    "    \n",
    "    #It gives title ,lat and lng\n",
    "    desc = [json.loads(i.get(\"data-map-marker\")) for i in soup_div_trails.find_all('div', {'class': 'row collapse trail'})]\n",
    "    \n",
    "    #NOTE: Here I have used a for loop because to itetate the data of variables url and desc\n",
    "    \n",
    "    for u,d in zip(url,desc):\n",
    "        new = dict()   #Create a empty dictionary name as new for storing the data in required formate\n",
    "        new['title'] = d['title']\n",
    "        new['lat'] = d['lat']\n",
    "        new['lng'] = d['lng']\n",
    "        ex,ex2,ex3 = get_data_from_url(u)\n",
    "        new['counties'] = ex['Counties']\n",
    "        new['states'] = ex['States']\n",
    "        new['length'] = ex['Length']\n",
    "        new['trail_end_points'] = ex['Trail end points']\n",
    "        new['trail_surfaces'] = ex2['Trail surfaces']\n",
    "        new['trail_category'] = ex2['Trail category']\n",
    "        new['trail_activities'] = ex3['Trail activities']\n",
    "        \n",
    "        trail_data.append(new)  #Append the new dictionary to a empty list trail_data\n",
    "    \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url_from_trail('atlanta')   #Tthis is how to call function by giving the name of required city or state trail data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file created for the purpose of storing data; atlanta_trail_data.json stores trails data of atlanta\n",
    "\n",
    "file = open(\"atlanta_trail_data.json\",\"w\")\n",
    "\n",
    "json.dump(trail_data,file)  #dumps the trails_data ny using json.dumps function\n",
    "file.close()  #closes the file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
